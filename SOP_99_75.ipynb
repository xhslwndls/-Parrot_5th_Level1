{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "SOP_99_75.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7a4a366-f470-4768-a6f7-a75ca53c48dc",
        "outputId": "38ea8105-b978-451f-a5aa-1065e5615139"
      },
      "source": [
        "!pip install einops\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.data import Dataset\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Flatten, Activation, MaxPooling2D, BatchNormalization, ReLU\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "from einops import rearrange\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "e7a4a366-f470-4768-a6f7-a75ca53c48dc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a794c2db-17e6-42c2-bb26-7e22941226e5"
      },
      "source": [
        "## Import Data"
      ],
      "id": "a794c2db-17e6-42c2-bb26-7e22941226e5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f89da516-7b1f-4454-a641-09371f0a3632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae76ae20-cb44-49f1-9d05-0ee9a25f38a2"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "id": "f89da516-7b1f-4454-a641-09371f0a3632",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e38adb8-6b62-4b01-a58c-ec00d21271e9"
      },
      "source": [
        "## Observe Data"
      ],
      "id": "7e38adb8-6b62-4b01-a58c-ec00d21271e9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f69f4a1e-95c1-4b7b-b436-09b1d2b39cb9",
        "outputId": "766bdcb5-904e-4984-8603-654c8ceb11f8"
      },
      "source": [
        "print('X_train: ', X_train.shape)\n",
        "print('X_test: ', X_test.shape)"
      ],
      "id": "f69f4a1e-95c1-4b7b-b436-09b1d2b39cb9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (60000, 28, 28)\n",
            "X_test:  (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "df3cd358-d442-419b-8f15-1a59f8233d0f",
        "outputId": "35fddac5-e56c-44f7-ebb3-ea8cf70e8929"
      },
      "source": [
        "fig = plt.figure(figsize=(9, 9))\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, 1 + i)\n",
        "    plt.tight_layout()\n",
        "    plt.imshow(X_train[i], cmap=\"gray\", interpolation=\"none\")\n",
        "    target = y_train[i]\n",
        "    plt.title(\"Ground Truth: {}\".format(int(target)))\n",
        "\n",
        "plt.show()"
      ],
      "id": "df3cd358-d442-419b-8f15-1a59f8233d0f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16f8e74d-61e3-4c81-b966-271e0ccc58c7"
      },
      "source": [
        "## Preprocessing"
      ],
      "id": "16f8e74d-61e3-4c81-b966-271e0ccc58c7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bde59564-7b3f-450c-b7b2-8cd00f4a55ca"
      },
      "source": [
        "target_size = 10   # 0 ~ 9, 총 9개\n",
        "\n",
        "### 주의: 흑백 데이터여도 channel 차원을 살려주어야 정상적으로 작동합니다\n",
        "X_train = rearrange(X_train, \"b h w -> b h w 1\")\n",
        "X_test = rearrange(X_test, \"b h w -> b h w 1\")\n",
        "\n",
        "X_train = X_train.astype(\"float32\") / (2 ** 8 - 1)   # 255로 scaling\n",
        "X_test = X_test.astype(\"float32\") / (2 ** 8 - 1)     # 255로 scaling\n",
        "\n",
        "y_train = to_categorical(y_train, target_size)       # 타겟을 정수로 변환\n",
        "y_test = to_categorical(y_test, target_size) "
      ],
      "id": "bde59564-7b3f-450c-b7b2-8cd00f4a55ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd1752df-ae19-4191-adc3-9014236da8b5"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
      ],
      "id": "fd1752df-ae19-4191-adc3-9014236da8b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDskH_kINW6z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "491998b7-4eb6-4407-eb25-2699ea8aec49"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=20,         # 무작위 회전 각도\n",
        "                                   width_shift_range=0.2,     # 가로 shift 비율 (전체 너비 대비 비율)\n",
        "                                   height_shift_range=0.2,    # 세로 shift 비율\n",
        "                                   brightness_range=None,     # 밝기 변환 범위 ex) (0.2, 0.8)\n",
        "                                   zoom_range=0.1,            # 확대 비율 (소수 1개 혹은 범위 지정 가능)\n",
        "                                   horizontal_flip=False,     # 무작위 수평 전환\n",
        "                                   vertical_flip=False,       # 무작위 수직 전환 (50% 확률)\n",
        "                                   shear_range=0.2,\n",
        "                                   rescale=None)              # 크기 재조절 인수 (보통 1./255를 많이 사용하지만 같은 비율로 valid data도 처리해줘야함)\n",
        "\n",
        "train_flow = train_datagen.flow(X_train, y_train, batch_size=256, shuffle=True)\n",
        "# val_flow = val_datagen.flow(X_val, y_val, batch_size=256, shuffle=False)\n",
        "\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "fig.tight_layout()\n",
        "\n",
        "# ImageDataGenerator 결과 프린트\n",
        "for X_batch, y_batch in train_datagen.flow(X_train, y_train, batch_size=9, shuffle=True):\n",
        "  for i in range(9):\n",
        "    plt.subplot(3, 3, 1 + i)\n",
        "    plt.imshow(X_batch[i].reshape(28, 28), cmap=\"gray\", interpolation=\"none\")\n",
        "    plt.title(np.argmax(y_batch[i]))\n",
        "  plt.show()\n",
        "  break\n"
      ],
      "id": "fDskH_kINW6z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76de6936-69dc-4d31-998c-2e1e68707363",
        "outputId": "e5f15f43-1984-4dde-bb73-56b249b97617"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "76de6936-69dc-4d31-998c-2e1e68707363",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 28, 28, 1)\n",
            "(12000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "(48000, 10)\n",
            "(12000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acddba37-8622-4071-9d95-6749d6495429",
        "outputId": "513296e8-6de2-41a0-a2a8-218721288f16"
      },
      "source": [
        "inputs = Input(shape=(28, 28, 1)) \n",
        "\n",
        "X = Conv2D(64, (3,3), padding='same', kernel_initializer='he_normal')(inputs)\n",
        "X = BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(X)\n",
        "X = ReLU()(X)\n",
        "X = Conv2D(64, (3,3), padding='same')(X)\n",
        "X = BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(X)\n",
        "X = ReLU()(X)\n",
        "    \n",
        "X = MaxPooling2D(2, 2)(X)\n",
        "#    tf.keras.layers.Dropout(0.8),\n",
        "    \n",
        "X = Conv2D(128, (3,3), padding='same')(X)\n",
        "X = BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(X)\n",
        "X = ReLU()(X)\n",
        "X = Conv2D(128, (3,3), padding='same')(X)\n",
        "X = BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(X)\n",
        "X = ReLU()(X)\n",
        "    \n",
        "X = MaxPooling2D(2,2)(X)\n",
        "#    tf.keras.layers.Dropout(0.8),\n",
        "\n",
        "X = Conv2D(256, (3,3), padding='same')(X)\n",
        "X = BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(X)\n",
        "X = ReLU()(X)\n",
        "X = Conv2D(256, (3,3), padding='same')(X)\n",
        "X = BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\")(X)\n",
        "X = ReLU()(X)\n",
        "    \n",
        "X = MaxPooling2D(2,2)(X)\n",
        "#    tf.keras.layers.Dropout(0.8),\n",
        "    \n",
        "X = Flatten()(X)\n",
        "X = Dense(1024, activation='relu')(X)\n",
        " #   tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "X = Dense(1024, activation='relu')(X)\n",
        " #   tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "\n",
        "X = Dropout(0.6)(X)\n",
        "outputs = Dense(10, activation='softmax')(X)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "id": "acddba37-8622-4071-9d95-6749d6495429",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              2360320   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 4,568,010\n",
            "Trainable params: 4,566,218\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "63e0e1e8-7819-43b0-a0fe-a684a66bb0c7",
        "outputId": "eba41147-c3d3-49f5-af26-ee8b02a6d914"
      },
      "source": [
        "\n",
        "optim = Adam(learning_rate=0.005)\n",
        "\n",
        "acc_lst = []\n",
        "loss_lst = []\n",
        "source = {\"Accuracy\" : acc_lst, \"Loss\" : loss_lst}\n",
        "\n",
        "for i in range(5):\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, verbose=1, mode='min')\n",
        "  mc = ModelCheckpoint(\"best{:02d}.ckpt\".format(i+1), monitor='val_loss', verbose=1, save_best_only=True, save_weight_only=True, mode='min', restore_best_weights=True)\n",
        "  rl = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, min_delta=0.001, min_lr=0.00001)\n",
        "\n",
        "  history = model.fit(train_flow, batch_size=256, epochs=50, validation_data=(X_val, y_val), verbose=1, callbacks=[es, mc, rl])\n",
        "  model.load_weights(\"best{:02d}.ckpt\".format(i+1))\n",
        "  loss, acc = model.evaluate(X_test, y_test)\n",
        "  print(\"Model accuracy: {:5.2f}%\".format(100*acc))\n",
        "  acc_lst.append(acc)\n",
        "  loss_lst.append(loss)\n",
        "  del model\n",
        "  \n",
        "  \n",
        "\n",
        "Data = pd.DataFrame(source)\n",
        "print(\"Average test accuracy : {:5.2f}%\".format(100*(sum(acc_lst)/len(acc_lst))))\n",
        "Data"
      ],
      "id": "63e0e1e8-7819-43b0-a0fe-a684a66bb0c7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "188/188 [==============================] - 57s 139ms/step - loss: 0.3538 - accuracy: 0.8835 - val_loss: 0.0656 - val_accuracy: 0.9807\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.06559, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0812 - accuracy: 0.9759 - val_loss: 0.0608 - val_accuracy: 0.9817\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.06559 to 0.06076, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0599 - accuracy: 0.9822 - val_loss: 0.0474 - val_accuracy: 0.9868\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.06076 to 0.04739, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0575 - accuracy: 0.9837 - val_loss: 0.0476 - val_accuracy: 0.9860\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.04739\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0476 - accuracy: 0.9861 - val_loss: 0.0352 - val_accuracy: 0.9898\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.04739 to 0.03523, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0421 - accuracy: 0.9876 - val_loss: 0.0577 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.03523\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 25s 133ms/step - loss: 0.0371 - accuracy: 0.9895 - val_loss: 0.0352 - val_accuracy: 0.9919\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.03523 to 0.03518, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 25s 133ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0177 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.03518 to 0.01769, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.0195 - val_accuracy: 0.9943\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01769\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.0186 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01769\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.0177 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01769 to 0.01765, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0178 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01765\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.0173 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01765 to 0.01734, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.0173 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01734 to 0.01730, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0171 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01730 to 0.01711, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.0171 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01711 to 0.01706, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.0169 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01706 to 0.01694, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0167 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.01694 to 0.01666, saving model to best01.ckpt\n",
            "INFO:tensorflow:Assets written to: best01.ckpt/assets\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0167 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01666\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.0170 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01666\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0168 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01666\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.0169 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01666\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0172 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01666\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0171 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01666\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.0168 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01666\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 25s 133ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.0171 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01666\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 25s 133ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.0167 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01666\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.0167 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01666\n",
            "Epoch 00028: early stopping\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0108 - accuracy: 0.9970\n",
            "Model accuracy: 99.70%\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.0441 - accuracy: 0.9879 - val_loss: 0.0351 - val_accuracy: 0.9905\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.03515, saving model to best02.ckpt\n",
            "INFO:tensorflow:Assets written to: best02.ckpt/assets\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0390 - accuracy: 0.9889 - val_loss: 0.0310 - val_accuracy: 0.9915\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.03515 to 0.03095, saving model to best02.ckpt\n",
            "INFO:tensorflow:Assets written to: best02.ckpt/assets\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0359 - accuracy: 0.9895 - val_loss: 0.0382 - val_accuracy: 0.9912\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.03095\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 0.0288 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.03095 to 0.02878, saving model to best02.ckpt\n",
            "INFO:tensorflow:Assets written to: best02.ckpt/assets\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0314 - accuracy: 0.9913 - val_loss: 0.0255 - val_accuracy: 0.9934\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.02878 to 0.02548, saving model to best02.ckpt\n",
            "INFO:tensorflow:Assets written to: best02.ckpt/assets\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0321 - accuracy: 0.9908 - val_loss: 0.0423 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.02548\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 0.0312 - val_accuracy: 0.9922\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.02548\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.0210 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.02548 to 0.02097, saving model to best02.ckpt\n",
            "INFO:tensorflow:Assets written to: best02.ckpt/assets\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.0185 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.02097 to 0.01852, saving model to best02.ckpt\n",
            "INFO:tensorflow:Assets written to: best02.ckpt/assets\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0162 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01852 to 0.01624, saving model to best02.ckpt\n",
            "INFO:tensorflow:Assets written to: best02.ckpt/assets\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0172 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01624\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0190 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01624\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.0161 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01624 to 0.01609, saving model to best02.ckpt\n",
            "INFO:tensorflow:Assets written to: best02.ckpt/assets\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0163 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01609\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0165 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01609\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.0162 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01609\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0161 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01609\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0163 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01609\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0162 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01609\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.0163 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01609\n",
            "Epoch 00020: early stopping\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0111 - accuracy: 0.9975\n",
            "Model accuracy: 99.75%\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 27s 136ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.0307 - val_accuracy: 0.9916\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.03073, saving model to best03.ckpt\n",
            "INFO:tensorflow:Assets written to: best03.ckpt/assets\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0271 - accuracy: 0.9924 - val_loss: 0.0267 - val_accuracy: 0.9930\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.03073 to 0.02673, saving model to best03.ckpt\n",
            "INFO:tensorflow:Assets written to: best03.ckpt/assets\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.0378 - val_accuracy: 0.9893\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.02673\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0264 - accuracy: 0.9925 - val_loss: 0.0241 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.02673 to 0.02407, saving model to best03.ckpt\n",
            "INFO:tensorflow:Assets written to: best03.ckpt/assets\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.0213 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.02407 to 0.02130, saving model to best03.ckpt\n",
            "INFO:tensorflow:Assets written to: best03.ckpt/assets\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0258 - accuracy: 0.9927 - val_loss: 0.0283 - val_accuracy: 0.9931\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.02130\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.0290 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.02130\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0184 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.02130 to 0.01837, saving model to best03.ckpt\n",
            "INFO:tensorflow:Assets written to: best03.ckpt/assets\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.0180 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.01837 to 0.01797, saving model to best03.ckpt\n",
            "INFO:tensorflow:Assets written to: best03.ckpt/assets\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.0186 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01797\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0170 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01797 to 0.01702, saving model to best03.ckpt\n",
            "INFO:tensorflow:Assets written to: best03.ckpt/assets\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0170 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01702\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0173 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01702\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0170 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01702 to 0.01699, saving model to best03.ckpt\n",
            "INFO:tensorflow:Assets written to: best03.ckpt/assets\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.0174 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01699\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0169 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01699 to 0.01693, saving model to best03.ckpt\n",
            "INFO:tensorflow:Assets written to: best03.ckpt/assets\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.0173 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01693\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0172 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01693\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0175 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01693\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0176 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01693\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.0174 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01693\n",
            "Epoch 00021: early stopping\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0104 - accuracy: 0.9968\n",
            "Model accuracy: 99.68%\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 27s 135ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0294 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02938, saving model to best04.ckpt\n",
            "INFO:tensorflow:Assets written to: best04.ckpt/assets\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.0256 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02938 to 0.02558, saving model to best04.ckpt\n",
            "INFO:tensorflow:Assets written to: best04.ckpt/assets\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 0.0261 - val_accuracy: 0.9929\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.02558\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0213 - accuracy: 0.9935 - val_loss: 0.0197 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.02558 to 0.01973, saving model to best04.ckpt\n",
            "INFO:tensorflow:Assets written to: best04.ckpt/assets\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.0214 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.01973\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0319 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01973\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.0175 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01973 to 0.01749, saving model to best04.ckpt\n",
            "INFO:tensorflow:Assets written to: best04.ckpt/assets\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0168 - val_accuracy: 0.9959\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01749 to 0.01681, saving model to best04.ckpt\n",
            "INFO:tensorflow:Assets written to: best04.ckpt/assets\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0169 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01681\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0169 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01681\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0161 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01681 to 0.01613, saving model to best04.ckpt\n",
            "INFO:tensorflow:Assets written to: best04.ckpt/assets\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0165 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01613\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0168 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01613\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.0164 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01613\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0162 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01613\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0159 - val_accuracy: 0.9962\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01613 to 0.01589, saving model to best04.ckpt\n",
            "INFO:tensorflow:Assets written to: best04.ckpt/assets\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0158 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01589 to 0.01579, saving model to best04.ckpt\n",
            "INFO:tensorflow:Assets written to: best04.ckpt/assets\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0160 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01579\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0161 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01579\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0161 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01579\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 26s 137ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0161 - val_accuracy: 0.9963\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01579\n",
            "Epoch 00021: early stopping\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0096 - accuracy: 0.9968\n",
            "Model accuracy: 99.68%\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 27s 137ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0233 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02327, saving model to best05.ckpt\n",
            "INFO:tensorflow:Assets written to: best05.ckpt/assets\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 26s 137ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.0193 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02327 to 0.01932, saving model to best05.ckpt\n",
            "INFO:tensorflow:Assets written to: best05.ckpt/assets\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.0273 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.01932\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.0309 - val_accuracy: 0.9912\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.01932\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.0174 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01932 to 0.01744, saving model to best05.ckpt\n",
            "INFO:tensorflow:Assets written to: best05.ckpt/assets\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.0166 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01744 to 0.01656, saving model to best05.ckpt\n",
            "INFO:tensorflow:Assets written to: best05.ckpt/assets\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.0185 - val_accuracy: 0.9953\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01656\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0180 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01656\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0180 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01656\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0180 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01656\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0180 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01656\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0179 - val_accuracy: 0.9955\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01656\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0177 - val_accuracy: 0.9957\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01656\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 25s 135ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0180 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01656\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0180 - val_accuracy: 0.9958\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01656\n",
            "Epoch 00015: early stopping\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0087 - accuracy: 0.9973\n",
            "Model accuracy: 99.73%\n",
            "Average test accuracy : 99.71%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9970</td>\n",
              "      <td>0.010776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9975</td>\n",
              "      <td>0.011057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9968</td>\n",
              "      <td>0.010367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.9968</td>\n",
              "      <td>0.009585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9973</td>\n",
              "      <td>0.008748</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy      Loss\n",
              "0    0.9970  0.010776\n",
              "1    0.9975  0.011057\n",
              "2    0.9968  0.010367\n",
              "3    0.9968  0.009585\n",
              "4    0.9973  0.008748"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b174ec48-1ed8-4375-9acf-456470fe9ad2"
      },
      "source": [
        "위에 있는 모델은\n",
        "\n",
        "https://tobigs.gitbook.io/tobigs/deep-learning/undefined/advanced-neural-net-2\n",
        "\n",
        "이 링크의 SOPCNN 모델을\n",
        "\n",
        "https://paperswithcode.com/paper/stochastic-optimization-of-plain\n",
        "\n",
        "SOPCNN 논문에 맞게 수정한 모델입니다!\n",
        "\n",
        "최대 정확도 99.75%\n",
        "\n",
        "## Sources\n",
        "https://towardsdatascience.com/the-quest-of-higher-accuracy-for-cnn-models-42df5d731faf"
      ],
      "id": "b174ec48-1ed8-4375-9acf-456470fe9ad2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8C8KGl0yznl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b43ce6-c020-4c7e-c855-410581d21ba6"
      },
      "source": [
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.load_weights(\"best{:02d}.ckpt\".format(acc_lst.index(max(acc_lst))+1))\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"model accuracy: {:5.2f}%\".format(100*acc))\n",
        "model.save(\"SOP_acc_99_75\")"
      ],
      "id": "P8C8KGl0yznl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0111 - accuracy: 0.9975\n",
            "model accuracy: 99.75%\n",
            "INFO:tensorflow:Assets written to: SOP_acc_99_75/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UC6lgMSgmPS",
        "outputId": "b8197268-d0cb-4d7d-bd6c-367ec5b566f4"
      },
      "source": [
        "new_model = load_model(\"SOP_acc_99_75\")\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"model accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "id": "0UC6lgMSgmPS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0111 - accuracy: 0.9975\n",
            "model accuracy: 99.75%\n"
          ]
        }
      ]
    }
  ]
}