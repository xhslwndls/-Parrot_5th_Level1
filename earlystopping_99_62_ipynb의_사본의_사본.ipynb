{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "earlystopping_99.62.ipynb의 사본의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYV9hWV63Sfk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, BatchNormalization, MaxPooling2D, LeakyReLU, ReLU, PReLU\n",
        "from tensorflow.keras.optimizers import RMSprop, Nadam, Adadelta, Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaYIMpBP3jPG"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Len-fmm3qEF",
        "outputId": "701eaf91-320a-4aa6-d570-d8514ed0953b"
      },
      "source": [
        "#Input data preprocessing\n",
        "X_train = X_train.reshape((60000, 28, 28, 1))\n",
        "X_test = X_test.reshape((10000, 28, 28, 1))\n",
        "#Output data preprocessing\n",
        "y_train = to_categorical(y_train, 10) # one-hot encoding, 1차원 -> 2차원\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "print(f\"X_train_shape: {X_train.shape}\") \n",
        "print(f\"X_test_shape: {X_test.shape}\")\n",
        "print(f\"y_train_shape: {y_train.shape}\")\n",
        "print(f\"y_test_shape: {y_test.shape}\")  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_shape: (60000, 28, 28, 1)\n",
            "X_test_shape: (10000, 28, 28, 1)\n",
            "y_train_shape: (60000, 10)\n",
            "y_test_shape: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WLjv01D4KNb"
      },
      "source": [
        "datagen_train = ImageDataGenerator(rotation_range = 10, \n",
        "                                   width_shift_range = 0.25, \n",
        "                                   height_shift_range = 0.25, \n",
        "                                   shear_range = 0.1,  \n",
        "                                   zoom_range = 0.4,\n",
        "                                   horizontal_flip = False) \n",
        "\n",
        "datagen_val = ImageDataGenerator() \n",
        "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau( \n",
        "    monitor='loss',    \n",
        "    factor=0.25,       \n",
        "    patience=2,        \n",
        "    verbose=1,         \n",
        "    mode=\"auto\",       \n",
        "    min_delta=0.0001,  \n",
        "    cooldown=0,        \n",
        "    min_lr=0.00001     \n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGFBWLDy4oh9",
        "outputId": "f8271781-4f7c-4827-9436-d70ae9419f1d"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),    \n",
        "    \n",
        "    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),##\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        " \n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 28, 28, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 28, 28, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 14, 14, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 14, 14, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 14, 14, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 7, 7, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 7, 7, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               590080    \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,926,794\n",
            "Trainable params: 1,924,106\n",
            "Non-trainable params: 2,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3MrUMws4sd0",
        "outputId": "d505d095-c808-4208-f6ab-69019f0455e8"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=300, restore_best_weights=True)\n",
        "history = model.fit(datagen_train.flow(X_train, y_train, batch_size=256),\n",
        "                              steps_per_epoch=len(X_train)//256,\n",
        "                              epochs=50,\n",
        "                              validation_data=(X_test, y_test),\n",
        "                              callbacks=[learning_rate_reduction, es],\n",
        "                              verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "234/234 - 42s - loss: 0.4480 - accuracy: 0.8558 - val_loss: 0.4586 - val_accuracy: 0.9703 - lr: 0.0010 - 42s/epoch - 180ms/step\n",
            "Epoch 2/50\n",
            "234/234 - 37s - loss: 0.1554 - accuracy: 0.9522 - val_loss: 0.0567 - val_accuracy: 0.9855 - lr: 0.0010 - 37s/epoch - 159ms/step\n",
            "Epoch 3/50\n",
            "234/234 - 37s - loss: 0.1155 - accuracy: 0.9636 - val_loss: 0.0707 - val_accuracy: 0.9814 - lr: 0.0010 - 37s/epoch - 158ms/step\n",
            "Epoch 4/50\n",
            "234/234 - 39s - loss: 0.0999 - accuracy: 0.9685 - val_loss: 0.0287 - val_accuracy: 0.9916 - lr: 0.0010 - 39s/epoch - 166ms/step\n",
            "Epoch 5/50\n",
            "234/234 - 37s - loss: 0.0942 - accuracy: 0.9705 - val_loss: 0.0290 - val_accuracy: 0.9913 - lr: 0.0010 - 37s/epoch - 158ms/step\n",
            "Epoch 6/50\n",
            "234/234 - 37s - loss: 0.0834 - accuracy: 0.9742 - val_loss: 0.0224 - val_accuracy: 0.9932 - lr: 0.0010 - 37s/epoch - 158ms/step\n",
            "Epoch 7/50\n",
            "234/234 - 37s - loss: 0.0829 - accuracy: 0.9740 - val_loss: 0.0293 - val_accuracy: 0.9910 - lr: 0.0010 - 37s/epoch - 157ms/step\n",
            "Epoch 8/50\n",
            "234/234 - 39s - loss: 0.0789 - accuracy: 0.9753 - val_loss: 0.0301 - val_accuracy: 0.9896 - lr: 0.0010 - 39s/epoch - 165ms/step\n",
            "Epoch 9/50\n",
            "234/234 - 37s - loss: 0.0748 - accuracy: 0.9762 - val_loss: 0.0218 - val_accuracy: 0.9925 - lr: 0.0010 - 37s/epoch - 157ms/step\n",
            "Epoch 10/50\n",
            "234/234 - 37s - loss: 0.0722 - accuracy: 0.9774 - val_loss: 0.0167 - val_accuracy: 0.9944 - lr: 0.0010 - 37s/epoch - 158ms/step\n",
            "Epoch 11/50\n",
            "234/234 - 37s - loss: 0.0713 - accuracy: 0.9778 - val_loss: 0.0275 - val_accuracy: 0.9914 - lr: 0.0010 - 37s/epoch - 156ms/step\n",
            "Epoch 12/50\n",
            "234/234 - 36s - loss: 0.0668 - accuracy: 0.9789 - val_loss: 0.0369 - val_accuracy: 0.9890 - lr: 0.0010 - 36s/epoch - 155ms/step\n",
            "Epoch 13/50\n",
            "234/234 - 37s - loss: 0.0609 - accuracy: 0.9812 - val_loss: 0.0274 - val_accuracy: 0.9918 - lr: 0.0010 - 37s/epoch - 158ms/step\n",
            "Epoch 14/50\n",
            "234/234 - 37s - loss: 0.0652 - accuracy: 0.9795 - val_loss: 0.0343 - val_accuracy: 0.9895 - lr: 0.0010 - 37s/epoch - 157ms/step\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "234/234 - 37s - loss: 0.0611 - accuracy: 0.9805 - val_loss: 0.0138 - val_accuracy: 0.9959 - lr: 0.0010 - 37s/epoch - 157ms/step\n",
            "Epoch 16/50\n",
            "234/234 - 37s - loss: 0.0450 - accuracy: 0.9853 - val_loss: 0.0155 - val_accuracy: 0.9957 - lr: 2.5000e-04 - 37s/epoch - 157ms/step\n",
            "Epoch 17/50\n",
            "234/234 - 37s - loss: 0.0435 - accuracy: 0.9858 - val_loss: 0.0141 - val_accuracy: 0.9957 - lr: 2.5000e-04 - 37s/epoch - 156ms/step\n",
            "Epoch 18/50\n",
            "234/234 - 37s - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.0147 - val_accuracy: 0.9951 - lr: 2.5000e-04 - 37s/epoch - 156ms/step\n",
            "Epoch 19/50\n",
            "234/234 - 36s - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0145 - val_accuracy: 0.9954 - lr: 2.5000e-04 - 36s/epoch - 156ms/step\n",
            "Epoch 20/50\n",
            "234/234 - 37s - loss: 0.0387 - accuracy: 0.9879 - val_loss: 0.0145 - val_accuracy: 0.9950 - lr: 2.5000e-04 - 37s/epoch - 156ms/step\n",
            "Epoch 21/50\n",
            "234/234 - 37s - loss: 0.0405 - accuracy: 0.9872 - val_loss: 0.0134 - val_accuracy: 0.9955 - lr: 2.5000e-04 - 37s/epoch - 158ms/step\n",
            "Epoch 22/50\n",
            "234/234 - 37s - loss: 0.0386 - accuracy: 0.9876 - val_loss: 0.0189 - val_accuracy: 0.9934 - lr: 2.5000e-04 - 37s/epoch - 158ms/step\n",
            "Epoch 23/50\n",
            "234/234 - 37s - loss: 0.0396 - accuracy: 0.9871 - val_loss: 0.0133 - val_accuracy: 0.9957 - lr: 2.5000e-04 - 37s/epoch - 157ms/step\n",
            "Epoch 24/50\n",
            "234/234 - 37s - loss: 0.0382 - accuracy: 0.9876 - val_loss: 0.0163 - val_accuracy: 0.9951 - lr: 2.5000e-04 - 37s/epoch - 157ms/step\n",
            "Epoch 25/50\n",
            "234/234 - 37s - loss: 0.0366 - accuracy: 0.9882 - val_loss: 0.0154 - val_accuracy: 0.9948 - lr: 2.5000e-04 - 37s/epoch - 158ms/step\n",
            "Epoch 26/50\n",
            "234/234 - 38s - loss: 0.0360 - accuracy: 0.9887 - val_loss: 0.0179 - val_accuracy: 0.9945 - lr: 2.5000e-04 - 38s/epoch - 162ms/step\n",
            "Epoch 27/50\n",
            "234/234 - 39s - loss: 0.0378 - accuracy: 0.9878 - val_loss: 0.0164 - val_accuracy: 0.9951 - lr: 2.5000e-04 - 39s/epoch - 168ms/step\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "234/234 - 37s - loss: 0.0379 - accuracy: 0.9874 - val_loss: 0.0148 - val_accuracy: 0.9955 - lr: 2.5000e-04 - 37s/epoch - 157ms/step\n",
            "Epoch 29/50\n",
            "234/234 - 37s - loss: 0.0330 - accuracy: 0.9896 - val_loss: 0.0116 - val_accuracy: 0.9962 - lr: 6.2500e-05 - 37s/epoch - 158ms/step\n",
            "Epoch 30/50\n",
            "234/234 - 37s - loss: 0.0329 - accuracy: 0.9896 - val_loss: 0.0123 - val_accuracy: 0.9961 - lr: 6.2500e-05 - 37s/epoch - 158ms/step\n",
            "Epoch 31/50\n",
            "234/234 - 37s - loss: 0.0321 - accuracy: 0.9899 - val_loss: 0.0132 - val_accuracy: 0.9958 - lr: 6.2500e-05 - 37s/epoch - 157ms/step\n",
            "Epoch 32/50\n",
            "234/234 - 37s - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.0122 - val_accuracy: 0.9960 - lr: 6.2500e-05 - 37s/epoch - 157ms/step\n",
            "Epoch 33/50\n",
            "234/234 - 37s - loss: 0.0292 - accuracy: 0.9907 - val_loss: 0.0124 - val_accuracy: 0.9960 - lr: 6.2500e-05 - 37s/epoch - 158ms/step\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "234/234 - 37s - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.0115 - val_accuracy: 0.9963 - lr: 6.2500e-05 - 37s/epoch - 157ms/step\n",
            "Epoch 35/50\n",
            "234/234 - 37s - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.0116 - val_accuracy: 0.9964 - lr: 1.5625e-05 - 37s/epoch - 157ms/step\n",
            "Epoch 36/50\n",
            "234/234 - 39s - loss: 0.0283 - accuracy: 0.9909 - val_loss: 0.0114 - val_accuracy: 0.9963 - lr: 1.5625e-05 - 39s/epoch - 165ms/step\n",
            "Epoch 37/50\n",
            "234/234 - 37s - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0118 - val_accuracy: 0.9962 - lr: 1.5625e-05 - 37s/epoch - 158ms/step\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "234/234 - 39s - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.0121 - val_accuracy: 0.9961 - lr: 1.5625e-05 - 39s/epoch - 166ms/step\n",
            "Epoch 39/50\n",
            "234/234 - 37s - loss: 0.0285 - accuracy: 0.9907 - val_loss: 0.0116 - val_accuracy: 0.9964 - lr: 1.0000e-05 - 37s/epoch - 158ms/step\n",
            "Epoch 40/50\n",
            "234/234 - 37s - loss: 0.0282 - accuracy: 0.9906 - val_loss: 0.0119 - val_accuracy: 0.9961 - lr: 1.0000e-05 - 37s/epoch - 156ms/step\n",
            "Epoch 41/50\n",
            "234/234 - 36s - loss: 0.0264 - accuracy: 0.9909 - val_loss: 0.0119 - val_accuracy: 0.9960 - lr: 1.0000e-05 - 36s/epoch - 155ms/step\n",
            "Epoch 42/50\n",
            "234/234 - 37s - loss: 0.0302 - accuracy: 0.9902 - val_loss: 0.0111 - val_accuracy: 0.9966 - lr: 1.0000e-05 - 37s/epoch - 157ms/step\n",
            "Epoch 43/50\n",
            "234/234 - 37s - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0114 - val_accuracy: 0.9959 - lr: 1.0000e-05 - 37s/epoch - 157ms/step\n",
            "Epoch 44/50\n",
            "234/234 - 37s - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.0114 - val_accuracy: 0.9961 - lr: 1.0000e-05 - 37s/epoch - 157ms/step\n",
            "Epoch 45/50\n",
            "234/234 - 37s - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.0114 - val_accuracy: 0.9962 - lr: 1.0000e-05 - 37s/epoch - 157ms/step\n",
            "Epoch 46/50\n",
            "234/234 - 37s - loss: 0.0282 - accuracy: 0.9909 - val_loss: 0.0117 - val_accuracy: 0.9959 - lr: 1.0000e-05 - 37s/epoch - 158ms/step\n",
            "Epoch 47/50\n",
            "234/234 - 39s - loss: 0.0290 - accuracy: 0.9907 - val_loss: 0.0114 - val_accuracy: 0.9961 - lr: 1.0000e-05 - 39s/epoch - 166ms/step\n",
            "Epoch 48/50\n",
            "234/234 - 37s - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.0118 - val_accuracy: 0.9960 - lr: 1.0000e-05 - 37s/epoch - 158ms/step\n",
            "Epoch 49/50\n",
            "234/234 - 37s - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.0116 - val_accuracy: 0.9964 - lr: 1.0000e-05 - 37s/epoch - 158ms/step\n",
            "Epoch 50/50\n",
            "234/234 - 39s - loss: 0.0275 - accuracy: 0.9910 - val_loss: 0.0115 - val_accuracy: 0.9962 - lr: 1.0000e-05 - 39s/epoch - 166ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4woO_z4vbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d025fa28-a7ba-4bc7-f592-5705c78a10b1"
      },
      "source": [
        "model.evaluate(X_test, y_test, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 2s 48ms/step - loss: 0.0115 - accuracy: 0.9962\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.011515125632286072, 0.9962000250816345]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPPK1MHmDMao"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}